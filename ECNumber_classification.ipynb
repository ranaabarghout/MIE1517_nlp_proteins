{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ECNumber_classification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["<br>\n","\n","## Imports"],"metadata":{"id":"TAcMbY69_5QE"}},{"cell_type":"code","source":["import time\n","import pickle\n","import numpy as np"],"metadata":{"id":"AO-KuMhdnAYP","executionInfo":{"status":"ok","timestamp":1648668812781,"user_tz":360,"elapsed":14,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from matplotlib.ticker import PercentFormatter"],"metadata":{"id":"oP_gpEK7So8I","executionInfo":{"status":"ok","timestamp":1648668812782,"user_tz":360,"elapsed":8,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"L-utLLqTk4Ij","executionInfo":{"status":"ok","timestamp":1648666363190,"user_tz":360,"elapsed":3407,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim import Adam"]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"10wfeZBHmzwx","executionInfo":{"status":"ok","timestamp":1648666363658,"user_tz":360,"elapsed":476,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Mount drive"],"metadata":{"id":"fclwtVf7nLNT"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeZht-FIm8OY","executionInfo":{"status":"ok","timestamp":1648666364852,"user_tz":360,"elapsed":1196,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}},"outputId":"4c514444-df44-4827-cf57-96a75eb1dccb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["<br>\n","\n","## Define constants"],"metadata":{"id":"MLCZkTMVCdhb"}},{"cell_type":"code","source":["TEST_SIZE = .2\n","EVAL_SIZE = .1\n","RANDOM_SEED = 30"],"metadata":{"id":"dJu0SOnrCjLE","executionInfo":{"status":"ok","timestamp":1648666364852,"user_tz":360,"elapsed":5,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","## Define classes"],"metadata":{"id":"_rH_gRj_rPwY"}},{"cell_type":"code","source":["class seqembData(Dataset):\n","    def __init__(self, inputs, labels):\n","        for input in inputs:\n","            assert input.shape[0] == len(labels)\n","        \n","        self.n = len(labels)\n","        self.labels = torch.as_tensor(labels)\n","        self.inputs = [torch.as_tensor(input).float() for input in inputs]\n","\n","    def __len__(self):\n","        return self.n\n","    \n","    def __getitem__(self, idx):\n","        return [input[idx] for input in self.inputs], self.labels[idx]"],"metadata":{"id":"VoQuMAwU-5Ju","executionInfo":{"status":"ok","timestamp":1648666364853,"user_tz":360,"elapsed":5,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class ecnumClassifier(nn.Module):\n","    def __init__(self, input_sizes, num_classes, hidden_size = 256, linear_sizes = [64, 64], drop_prob = .2):\n","        super().__init__()\n","\n","        # Input processing layers\n","        proc_layers = []\n","        for size in input_sizes:\n","            proc_layer = nn.Sequential(\n","                nn.Dropout(p = drop_prob),\n","                nn.Linear(size, hidden_size),\n","                nn.ReLU(),\n","                nn.BatchNorm1d(hidden_size)\n","            )\n","            proc_layers.append(proc_layer)\n","        self.proc_layers = nn.ModuleList(proc_layers)\n","\n","        # Linear layers\n","        input_size = hidden_size * len(input_sizes)\n","        linear_layers = []\n","        for output_size in linear_sizes:\n","            linear_layers.append(nn.Dropout(p = drop_prob))\n","            linear_layers.append(nn.Linear(input_size, output_size))\n","            linear_layers.append(nn.ReLU())\n","            linear_layers.append(nn.BatchNorm1d(output_size))\n","            input_size = output_size\n","        self.linear_layers = nn.Sequential(*linear_layers)\n","\n","        # Output layer        \n","        self.output_layer = nn.Linear(input_size, num_classes)\n","    \n","    def forward(self, x_list):\n","        # Process inputs by independent processign layers\n","        y_list = []\n","        for i, proc_layer in enumerate(self.proc_layers):\n","            x = self.dropout(x_list[i])\n","            y_list.append(proc_layer(x))\n","\n","        # Concat together            \n","        y = torch.cat(y_list, dim = 1)\n","\n","        # Pass through linear layers\n","        z = self.linear_layers(y)\n","\n","        # Get output\n","        o = self.output_layer(z)\n","\n","        return o"],"metadata":{"id":"uhcTgcXlnM7O","executionInfo":{"status":"ok","timestamp":1648671336753,"user_tz":360,"elapsed":171,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":120,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","\n","Aux. functions"],"metadata":{"id":"03WpkmnYI6fl"}},{"cell_type":"code","source":["def get_preds(logits):\n","    proba = torch.log_softmax(logits, dim = 1)\n","    _, preds = torch.max(proba, dim = 1)\n","    return proba, preds\n","\n","def calc_acc(preds, targets):\n","    return torch.sum(preds == targets) / len(targets)"],"metadata":{"id":"MXthp_VTI9MI","executionInfo":{"status":"ok","timestamp":1648666364854,"user_tz":360,"elapsed":5,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["class ecnumTrainer():\n","    def __init__(self, model, train_data, eval_data = None, batch_size = 32, learning_rate = 1e-4, decay = 1e-5, device = 'cpu'):\n","\n","        # Set device\n","        self.device = device\n","\n","        # Set model\n","        self.model = model\n","        \n","        # Set train data loader\n","        self.train_loader = DataLoader(\n","            train_data,\n","            batch_size = batch_size,\n","            shuffle = True\n","        )\n","\n","        # Set optimizer\n","        self.optimizer = Adam(\n","            self.model.parameters(),\n","            lr = learning_rate,\n","            weight_decay = decay\n","        )\n","\n","        # Set eval data loader\n","        if eval_data is not None:\n","            self.eval_loader = DataLoader(\n","                eval_data, \n","                batch_size=len(eval_data),\n","                shuffle = False\n","            )\n","        else:\n","            self.eval_loader = None\n","\n","        # Set loss function\n","        self.loss_func = nn.CrossEntropyLoss() \n","\n","    def validate(self):\n","        self.model.eval()\n","        with torch.no_grad():\n","            inputs, targets = next(iter(self.eval_loader))\n","            inputs = [input.to(self.device) for input in inputs]\n","            logits = self.model(inputs)\n","\n","            # Calc error\n","            error = self.loss_func(logits, targets)\n","            error = error.item()\n","\n","            # Get predictions\n","            proba, preds = get_preds(logits)\n","\n","            # Assess accuracy\n","            acc = calc_acc(preds, targets)\n","            acc = acc.item()\n"," \n","        return error, acc\n","\n","    def train(self, num_epochs = 20, verbosity = 10):\n","\n","        # Train track container\n","        train_track = {'error' : [], 'accuracy' : []}\n","        if self.eval_loader is not None:\n","            eval_track = {'error' : [], 'accuracy' : []}\n","        else:\n","            eval_track = None\n","\n","        # Set device\n","        self.model.to(self.device)\n","        \n","        # Training\n","        n = len(self.train_loader)\n","        start = time.time()\n","        for epoch in range(num_epochs):\n","            self.model.train()\n","            train_error = 0.    \n","            train_acc = 0.        \n","            for i, (inputs, targets) in enumerate(self.train_loader):\n","                inputs = [input.to(self.device) for input in inputs]\n","                logits = self.model(inputs)\n","\n","                # Calc error and do training step\n","                error = self.loss_func(logits, targets)\n","                self.optimizer.zero_grad()\n","                error.backward()\n","                self.optimizer.step()\n","                error = error.item()\n","\n","                # Get predictions\n","                _, preds = get_preds(logits)\n","\n","                # Calculate accuracy\n","                acc = calc_acc(preds, targets)\n","                acc = acc.item()\n","\n","                # Report\n","                if verbosity > 0:\n","                    if (i + 1) % verbosity == 0:\n","                        print('Epoch: {}/{}\\t Batch: {}/{}\\t Error: {:1.3f}\\t Accuracy: {:1.2f}'.format(epoch + 1, num_epochs, i + 1, n, error, acc))\n","\n","                # Increment training error and accuracy              \n","                train_error += error                \n","                train_acc += acc\n","\n","            # Average training error\n","            train_error /= n      \n","            train_track['error'].append(train_error)\n","\n","            # Average training accuracy\n","            train_acc /= n\n","            train_track['accuracy'].append(train_acc)\n","\n","            # Validation\n","            if self.eval_loader is not None:\n","                eval_error, eval_acc = self.validate()\n","                eval_track['error'].append(eval_error)\n","                eval_track['accuracy'].append(eval_acc)\n","\n","                print('\\n')\n","                print('\\t Epoch: {}'.format(epoch + 1))\n","                print('\\t Validation loss: {:1.2f}'.format(eval_error))\n","                print('\\t Validation accuracy: {:1.2f}'.format(eval_acc))\n","                print('\\t Elapsed time: {:1.1f}'.format(time.time()-start))\n","                print('\\n')\n","\n","        return train_track, eval_track\n"],"metadata":{"id":"W2hU5hhFuxjh","executionInfo":{"status":"ok","timestamp":1648666850677,"user_tz":360,"elapsed":394,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["def plot_tracks(errors, accuracies, eval_errors = None, eval_accuracies = None, title = None, file_name = None):\n","    # Prepare x-values\n","    x = np.arange(len(errors)) + 1.\n","    \n","    # Prepare plot\n","    fig, ax1 = plt.subplots()\n","    ax1.set_xlabel('Epochs [#]')\n","    ax1.minorticks_on()\n","    ax1.grid()\n","    \n","    # Plot errors\n","    color = 'maroon'\n","    ax1.plot(x, errors, color=color)    \n","    ax1.set_ylabel('Cross-Entropy Loss', color=color)\n","    ax1.tick_params(axis='y', labelcolor=color)\n","    # Plot evaluation errors\n","    if eval_errors:\n","        ax1.plot(x, eval_errors, color=color, linestyle='dashed')    \n","\n","    # Plot performance\n","    color = 'steelblue'\n","    ax2 = ax1.twinx()\n","    ax2.plot(x, accuracies, color=color)\n","    ax2.set_ylabel('Accuracy [%]', color=color)\n","    ax2.tick_params(axis='y', labelcolor=color)\n","    ax2.yaxis.set_major_formatter(PercentFormatter())\n","    # Plot evaluation accuracies\n","    if eval_accuracies :\n","        ax2.plot(x, eval_accuracies, color=color, linestyle='dashed')\n","\n","\n","    # Add title\n","    if title is not None:\n","        plt.suptitle(title)\n","\n","    # Plot\n","    fig.tight_layout() \n","    if file_name is None:\n","        plt.show()\n","    else:\n","        plt.savefig(file_name, dpi = 100)\n"],"metadata":{"id":"dg09uFVfFmXf","executionInfo":{"status":"ok","timestamp":1648670236545,"user_tz":360,"elapsed":336,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","## Load data and create datasets (train, eval, test)"],"metadata":{"id":"F9G6NvVq_-Bf"}},{"cell_type":"code","source":["path = '/content/drive/Othercomputers/My MacBook Pro/MIE1517_nlp_proteins/embeddings/esm_embeddings.p'\n","with open(path, 'rb') as f:\n","    esm_embedding_output = pickle.load(f)"],"metadata":{"id":"RbZBqKXw_0ZO","executionInfo":{"status":"ok","timestamp":1648666365088,"user_tz":360,"elapsed":2,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/Othercomputers/My MacBook Pro/MIE1517_nlp_proteins/embeddings/protalbert_embeddings.p'\n","with open(path, 'rb') as f:\n","    protalbert_embedding_output = pickle.load(f)"],"metadata":{"id":"WWiAyNfUARcV","executionInfo":{"status":"ok","timestamp":1648666367034,"user_tz":360,"elapsed":1948,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Assert data integrity"],"metadata":{"id":"aXgytXB9AqIw"}},{"cell_type":"code","source":["assert esm_embedding_output['seq_labels'] == protalbert_embedding_output['seq_labels']"],"metadata":{"id":"xH3dODYuAayo","executionInfo":{"status":"ok","timestamp":1648666367035,"user_tz":360,"elapsed":6,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Select labels and inputs"],"metadata":{"id":"4YurfgyZERkL"}},{"cell_type":"code","source":["labels = esm_embedding_output['seq_labels']\n","inputs = [\n","    esm_embedding_output['seq_embeddings'],       # Embeddings from esm\n","    protalbert_embedding_output['seq_embeddings']  # Embeddings from protAlbert\n","]"],"metadata":{"id":"7pFdL2KVAki_","executionInfo":{"status":"ok","timestamp":1648666367035,"user_tz":360,"elapsed":5,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Encode labels"],"metadata":{"id":"-hQPFPUuEUzD"}},{"cell_type":"code","source":["ec_encoder = LabelEncoder()\n","labels = ec_encoder.fit_transform(np.array(labels))"],"metadata":{"id":"zf20TSF7DEyd","executionInfo":{"status":"ok","timestamp":1648666367035,"user_tz":360,"elapsed":4,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Train test split"],"metadata":{"id":"mqD-pn_6EWX7"}},{"cell_type":"code","source":["train_idx, test_idx = train_test_split(\n","    range(len(labels)), \n","    test_size=TEST_SIZE, \n","    random_state=RANDOM_SEED\n",")\n","\n","train_idx, eval_idx = train_test_split(\n","    train_idx, \n","    test_size=EVAL_SIZE,\n","    random_state = RANDOM_SEED\n",")"],"metadata":{"id":"qQBwLknUCHOk","executionInfo":{"status":"ok","timestamp":1648666367035,"user_tz":360,"elapsed":4,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Create datasets"],"metadata":{"id":"w8-_IAozEYiM"}},{"cell_type":"code","source":["# Train data\n","train_labels = labels[train_idx]\n","train_inputs = [input[train_idx] for input in inputs]\n","train_dataset = seqembData(train_inputs, train_labels)\n","\n","# Eval data\n","eval_labels = labels[eval_idx]\n","eval_inputs = [input[eval_idx] for input in inputs]\n","eval_dataset = seqembData(eval_inputs, eval_labels)\n","\n","# Test data\n","test_labels = labels[test_idx]\n","test_inputs = [input[test_idx] for input in inputs]\n","test_dataset = seqembData(test_inputs, test_labels)"],"metadata":{"id":"m-svU0lvCQRr","executionInfo":{"status":"ok","timestamp":1648666367429,"user_tz":360,"elapsed":398,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","## Train the model"],"metadata":{"id":"dOLl5d0GEas_"}},{"cell_type":"markdown","source":["<br>\n","\n","Init model"],"metadata":{"id":"J5kz9CZfFA9A"}},{"cell_type":"code","source":["input_sizes = [input.shape[1] for input in train_inputs]\n","num_classes = len(ec_encoder.classes_)\n","model = ecnumClassifier(\n","    input_sizes = input_sizes, \n","    num_classes = num_classes,\n","    hidden_size = 256,\n","    linear_sizes = [64, 64],\n","    drop_prob = .4\n",")"],"metadata":{"id":"zI2H7v7UEPYq","executionInfo":{"status":"ok","timestamp":1648671345699,"user_tz":360,"elapsed":168,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["model = model.float()"],"metadata":{"id":"OTMNyW_fHNT4","executionInfo":{"status":"ok","timestamp":1648671345980,"user_tz":360,"elapsed":2,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":122,"outputs":[]},{"cell_type":"markdown","source":["<br>\n","\n","Select device"],"metadata":{"id":"aXw5Q-KnFZmU"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2EmhvDChFStY","executionInfo":{"status":"ok","timestamp":1648671346362,"user_tz":360,"elapsed":3,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}},"outputId":"185b3edd-ba69-4c37-e5c7-32a9132d4413"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":123}]},{"cell_type":"markdown","source":["<br>\n","\n","Init trainer"],"metadata":{"id":"-LOkKDleFFo_"}},{"cell_type":"code","source":["trainer = ecnumTrainer(\n","    model,\n","    train_dataset,\n","    eval_dataset,\n","    batch_size = 32,\n","    learning_rate = 1e-4,\n","    device = device\n",")"],"metadata":{"id":"-cONRyBrE2Ut","executionInfo":{"status":"ok","timestamp":1648671346983,"user_tz":360,"elapsed":1,"user":{"displayName":"Tomas Tokar","userId":"05061769783370039932"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["train_track, eval_track = trainer.train(num_epochs = 25, verbosity = 20)"],"metadata":{"id":"R9dYT_STFchE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_tracks(\n","    train_track['error'],\n","    train_track['accuracy'],\n","    eval_errors = eval_track['error'],\n","    eval_accuracies = eval_track['accuracy'],\n","    file_name = '/content/drive/Othercomputers/My MacBook Pro/MIE1517_nlp_proteins/results/tracks.png'\n",")"],"metadata":{"id":"wehYWLGSTvni"},"execution_count":null,"outputs":[]}]}